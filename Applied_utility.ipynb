{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4026d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b082cf9",
   "metadata": {},
   "source": [
    "#### Load data and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330d834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./JM006_0901_whole.csv')\n",
    "df = df.dropna(subset=['milkweightlbs'])\n",
    "df = df.dropna(subset=['cells'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b59e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "disease_group = df[df['disease'] == 1]\n",
    "unique_disease_cow_ids = disease_group['cow_id'].unique()\n",
    "train_cow_ids, test_cow_ids = train_test_split(unique_disease_cow_ids, test_size=0.25, random_state=42)\n",
    "train_disease = disease_group[disease_group['cow_id'].isin(train_cow_ids)]\n",
    "#train_disease = train_disease[df['disease_in'] > 14]\n",
    "#train_disease = train_disease[df['disease_in'] <= 14][df['disease_in'] >= 11]\n",
    "#train_disease = train_disease[df['disease_in'] <= 11][df['disease_in'] >= 8]\n",
    "#train_disease = train_disease[df['disease_in'] <= 7][df['disease_in'] >= 6]\n",
    "#train_disease = train_disease[df['disease_in'] <= 5][df['disease_in'] >= 4]\n",
    "#train_disease = train_disease[df['disease_in'] == 3]\n",
    "#train_disease = train_disease[df['disease_in'] == 2]\n",
    "train_disease = train_disease[df['disease_in'] == 1]\n",
    "test_disease = disease_group[disease_group['cow_id'].isin(test_cow_ids)]\n",
    "#test_disease = test_disease[df['disease_in'] > 14]\n",
    "#test_disease = test_disease[df['disease_in'] <= 14][df['disease_in'] >= 11]\n",
    "#test_disease = test_disease[df['disease_in'] <= 11][df['disease_in'] >= 8]\n",
    "#test_disease = test_disease[df['disease_in'] <= 7][df['disease_in'] >= 6]\n",
    "#test_disease = test_disease[df['disease_in'] <= 5][df['disease_in'] >= 4]\n",
    "#test_disease = test_disease[df['disease_in'] == 3]\n",
    "#test_disease = test_disease[df['disease_in'] == 2]\n",
    "test_disease = test_disease[df['disease_in'] == 1]\n",
    "\n",
    "health_group = df[df['disease'] == 0]\n",
    "unique_health_cow_ids = health_group['cow_id'].unique()\n",
    "selected_train_health_cow_ids = np.random.choice(unique_health_cow_ids, size=len(train_cow_ids), replace=False)\n",
    "selected_test_health_cow_ids = np.random.choice(\n",
    "    [id for id in unique_health_cow_ids if id not in selected_train_health_cow_ids],\n",
    "    size=len(test_cow_ids),\n",
    "    replace=False\n",
    ")\n",
    "train_health = health_group[health_group['cow_id'].isin(selected_train_health_cow_ids)]\n",
    "test_health = health_group[health_group['cow_id'].isin(selected_test_health_cow_ids)]\n",
    "avg_train_rows = train_disease.groupby('cow_id').size().mean()\n",
    "avg_test_rows = test_disease.groupby('cow_id').size().mean()\n",
    "train_health = train_health.groupby('cow_id').apply(lambda x: x.sample(n=int(avg_train_rows), replace=True)).reset_index(drop=True)\n",
    "test_health = test_health.groupby('cow_id').apply(lambda x: x.sample(n=int(avg_test_rows), replace=True)).reset_index(drop=True)\n",
    "train_health = train_health.sample(n=train_disease.shape[0], random_state=42)\n",
    "test_health = test_health.sample(n=test_disease.shape[0], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b71df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([train_disease, train_health])\n",
    "X_train_np = np.hstack((X_train.iloc[:,1:488].values[:, ::-1], X_train['milkweightlbs_sca'].values.reshape(-1, 1), X_train['cells_sca'].values.reshape(-1, 1), X_train['parity_sca'].values.reshape(-1, 1)))\n",
    "y_train = X_train['disease']\n",
    "\n",
    "X_test = pd.concat([test_disease, test_health])\n",
    "X_test_np = np.hstack((X_test.iloc[:,1:488].values[:, ::-1], X_test['milkweightlbs_sca'].values.reshape(-1, 1), X_test['cells_sca'].values.reshape(-1, 1), X_test['parity_sca'].values.reshape(-1, 1)))\n",
    "y_test = X_test['disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bda0d",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade90a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class MLPClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, hidden_layer_sizes=(100,), activation='relu', epochs=200, batch_size=32):\n",
    "        self.input_shape = input_shape  \n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hidden_layer_sizes[0], activation=self.activation, input_shape=(self.input_shape,)))\n",
    "        \n",
    "        for layer_size in self.hidden_layer_sizes[1:]:\n",
    "            model.add(Dense(layer_size, activation=self.activation))\n",
    "            \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb584c",
   "metadata": {},
   "source": [
    "#### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f75be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 658us/step\n",
      "7/7 [==============================] - 0s 428us/step\n",
      "Accuracy: 0.7546296296296297\n",
      "Sensitivity: 0.6574074074074074\n",
      "Specificity: 0.8518518518518519\n",
      "3/3 [==============================] - 0s 621us/step\n",
      "Accuracy: 0.8076923076923077\n",
      "Sensitivity: 0.6410256410256411\n",
      "Specificity: 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifierCustom(input_shape=X_train_np.shape[1], hidden_layer_sizes=(32, 128, 32)) # 200, 200, 400, 64\n",
    "clf.fit(X_train_np, y_train) \n",
    "clf.predict_proba(X_test_np) \n",
    "\n",
    "# training set\n",
    "predicted_outcome = clf.predict(X_train_np).tolist()\n",
    "true_outcome = y_train.tolist()\n",
    "TP = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 1 and t == 1])\n",
    "TN = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 0 and t == 0])\n",
    "FP = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 1 and t == 0])\n",
    "FN = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 0 and t == 1])\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "\n",
    "# test set\n",
    "predicted_outcome = clf.predict(X_test_np).tolist()\n",
    "true_outcome = y_test.tolist()\n",
    "TP = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 1 and t == 1])\n",
    "TN = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 0 and t == 0])\n",
    "FP = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 1 and t == 0])\n",
    "FN = sum([1 for p, t in zip(predicted_outcome, true_outcome) if p == 0 and t == 1])\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0791ae2",
   "metadata": {},
   "source": [
    "#### Get the feature importance from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f404ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00097806, 0.00111117, 0.00137647, ..., 0.09970991, 0.021165  ,\n",
       "        0.09923735],\n",
       "       [0.00060821, 0.00065856, 0.00081852, ..., 0.13882788, 0.21855034,\n",
       "        0.07586302],\n",
       "       [0.00057291, 0.00042864, 0.00061508, ..., 0.11296591, 0.01443004,\n",
       "        0.05450489],\n",
       "       ...,\n",
       "       [0.00073105, 0.00053838, 0.00068968, ..., 0.06925765, 0.02641927,\n",
       "        0.0799501 ],\n",
       "       [0.00088795, 0.00072569, 0.00075262, ..., 0.25082266, 0.03399358,\n",
       "        0.20403323],\n",
       "       [0.0003819 , 0.000388  , 0.00065671, ..., 0.2128078 , 0.04314329,\n",
       "        0.04142768]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifierCustom(input_shape=X_train_np.shape[1], hidden_layer_sizes=(32, 128, 32)) # 200, 200, 400, 64\n",
    "clf.fit(X_train_np, y_train)  \n",
    "\n",
    "explainer = shap.GradientExplainer(clf.model, [X_train_np, y_train])\n",
    "shap_values = explainer.shap_values(X_test_np)  \n",
    "shap_values = np.array(shap_values)\n",
    "shap_values = shap_values.reshape(X_test_np.shape[0], X_test_np.shape[1])\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf8064",
   "metadata": {},
   "source": [
    "#### Get the predictive probability of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d013096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9329765 ],\n",
       "       [0.89401335],\n",
       "       [0.43075615],\n",
       "       [0.7833198 ],\n",
       "       [0.68400973],\n",
       "       [0.6231455 ],\n",
       "       [0.18733844],\n",
       "       [0.7760402 ],\n",
       "       [0.92181206],\n",
       "       [0.9422417 ],\n",
       "       [0.38584274],\n",
       "       [0.9940436 ],\n",
       "       [0.8154259 ],\n",
       "       [0.6417288 ],\n",
       "       [0.47880995],\n",
       "       [0.23390047],\n",
       "       [0.9043546 ],\n",
       "       [0.30890784],\n",
       "       [0.2985193 ],\n",
       "       [0.9104303 ],\n",
       "       [0.9094698 ],\n",
       "       [0.7229282 ],\n",
       "       [0.06205786],\n",
       "       [0.71774477],\n",
       "       [0.9147808 ],\n",
       "       [0.20482156],\n",
       "       [0.32362768],\n",
       "       [0.989471  ],\n",
       "       [0.70395577],\n",
       "       [0.47836742],\n",
       "       [0.91591823],\n",
       "       [0.28025502],\n",
       "       [0.792959  ],\n",
       "       [0.3854156 ],\n",
       "       [0.87864107],\n",
       "       [0.91199774],\n",
       "       [0.8506606 ],\n",
       "       [0.6040987 ],\n",
       "       [0.27852225],\n",
       "       [0.08057581],\n",
       "       [0.8549368 ],\n",
       "       [0.37218174],\n",
       "       [0.5187405 ],\n",
       "       [0.3088027 ],\n",
       "       [0.0782803 ],\n",
       "       [0.2189287 ],\n",
       "       [0.2065774 ],\n",
       "       [0.12670957],\n",
       "       [0.42073497],\n",
       "       [0.12882106],\n",
       "       [0.18154408],\n",
       "       [0.25194997],\n",
       "       [0.32155254],\n",
       "       [0.22229792],\n",
       "       [0.301087  ],\n",
       "       [0.12570871],\n",
       "       [0.268081  ],\n",
       "       [0.24028338],\n",
       "       [0.34158945],\n",
       "       [0.11903406],\n",
       "       [0.19004984],\n",
       "       [0.53491724],\n",
       "       [0.42568386],\n",
       "       [0.47022483],\n",
       "       [0.13747676],\n",
       "       [0.1226623 ],\n",
       "       [0.09732597],\n",
       "       [0.08945043],\n",
       "       [0.21457595],\n",
       "       [0.35437942],\n",
       "       [0.09341811],\n",
       "       [0.2943134 ],\n",
       "       [0.26003423],\n",
       "       [0.26861882],\n",
       "       [0.14480072],\n",
       "       [0.2428081 ],\n",
       "       [0.31921038],\n",
       "       [0.24143822]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f99f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
